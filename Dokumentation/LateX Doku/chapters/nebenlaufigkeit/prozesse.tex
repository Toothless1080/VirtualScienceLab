% !TeX root = ../../pythonTutorial.tex
\subsection{Prozesse}
\label{prozesse:subsection:prozesse}

Die bisher betrachteten Beispiele und Aufgabe waren nicht CPU-gebunden, weshalb die Auswirkungen des
in Abschnit \ref{parallelität_in_python:subsection:parallelität_in_python} angesprochenen GILs nicht
ersichtlich wurden. 
Wird nun aber das folgende Beispiel betrachtet, in dem die Anzahl der Primzahlen im Zahlenbereich 1
bis 10 Millionen gesucht wird, ist dies nicht mehr der Fall.
Hierzu wird die \hyperref[prozesse:lst:count_primes]{Methode \lstinline$countPrims()$} betrachtet,
die eine Liste an Zahlen entgegen nimmt und die Anzahl der enthaltenen Primzahlen ausgibt.

\label{prozesse:lst:count_primes}
\lstinputlisting[language=Python,linerange={1-2,8-23}]{chapters/nebenlaufigkeit/src/primzahlen_threads.py}

Es werden nun 10 Threads erzeugt, die jeweils für 1 Millionen Zahlen prüfen, ob es sich bei ihnen um
eine Primzahl handelt.
Zusätzlich wird die Zeit gemessen, die die Threads benötigen, um die Primzahlen zu zählen.

\label{prozesse:lst:primzahlen_threads}
\lstinputlisting[language=Python, linerange={1-2,25-42}]{chapters/nebenlaufigkeit/src/primzahlen_threads.py}

Wird diese Programm ausgeführt, kann eine mögliche Ausgabe wie folgt aussehen:
\label{prozesse:lst:thread_ausgabe}
\begin{lstlisting}
Found  67883  primes
Found  78498  primes
Found  70435  primes
Found  63799  primes
Found  65367  primes
Found  64336  primes
Found  66330  primes
Found  62712  primes
Found  62090  primes
Found  63129  primes
Finished in  102.9065528  seconds
\end{lstlisting}

Um nun den Effekt des GILs zu zeigen, wird die selbe Aufgabe durch mehrere Prozesse gelöst.
Hierzu bietet Python im \lstinline$multiprocessing$-Modul die Klasse \lstinline$Process$ an.
Die API, mit der neue Prozesse in Python erzeugt und gestartet werden, ähnelt der des
\lstinline$threading$-Moduls.
Demnach muss der Code nur minimal angepasst werden, um Primzahlen von Prozessen zählen zu lassen:
\label{prozesse:lst:primzahlen_prozesse}
\lstinputlisting[language=Python,linerange={1-2,25-43}]{chapters/nebenlaufigkeit/src/primzahlen_prozesse.py}

Wird dieses Programm ebenfalls ausgeführt, ist es möglich, die Primzahlen schneller zu zählen.
Eine mögliche Ausgabe kann wie folgt aussehen:
\label{prozesse:lst:prozess_ausgabe}
\begin{lstlisting}
Found  78498  primes
Found  70435  primes
Found  67883  primes
Found  65367  primes
Found  66330  primes
Found  64336  primes
Found  63129  primes
Found  63799  primes
Found  62712  primes
Found  62090  primes
Finished in  29.6911255  seconds
\end{lstlisting}

Beide Varianten erhalten das selbe Ergebniss, allerdings sind die Prozesse knapp 70 Sekunden schneller.
Ein größerer unterschied der beiden Varianten ist die Zeile \lstinline$if __name__ == ''__main__''$.
Diese Zeile ist im \hyperref[prozesse:lst:primzahen_prozesse]{Prozess-Beispiel} notwendig, da der
Programmcode innerhalb des \lstinline$if$-Statements ansonsten jedesmal ausgeführt wird, wenn das
Modul importiert wird.
Wird ein neuer Prozess gestartet, lädt der neue Python-Interpreter das Modul ein zweites mal.
Sobald er nun die Codezeile erreicht, in der der neue Prozess gestartet wurde, wird ein dritter Prozesse
gestartet, dessen Python-Interpreter das Modul ein drittes mal lädt.
Somit werden solange Prozesse erzeugt, bis das System keine Ressourcen mehr zur Verfügung hat.
Durch Angabe des \lstinline$if$-Statements ist es garantiert, dass der enthaltene Code nur einmal
ausgeführt wird, wenn das Programm gestartet wird.

\subsubsection{Prozess Objekte}
\label{prozesse:subsubsection:prozess_objekte}

Wie aus dem betrachteten \hyperref[prozesse:lst:primzahen_prozesse]{Prozess-Beispiel} erkenntlich ist,
ist die Verwendung der \lstinline$Process$-Klasse sehr stark an die der \lstinline$Thread$-Klasse angelehnt.
Genau genommen gibt es jede Methode von \lstinline$Thread$ auch in \lstinline$Process$.
Sogar die Konstruktoren sind identisch.
Der \lstinline$group$-Parameter des \lstinline$Process$-Konstruktors existert allerdings nur zur
Kompatibilität zum Konstruktor der \lstinline$Thread$-Klasse.
Der Aufruf von \lstinline$join()$ gibt immer \lstinline$None$ zurück, auch wenn der optionale Timeout
abgelaufen ist.
Um zu prüfen, ob der entsprechende Prozess tatsächlich beendet wurde, ist über seinen
\lstinline$exitcode$
einsehbar.
Es ist zu bemerken, dass ein Dämon-Prozess keine weiteren Kindprozesse starten kann.
Sobald sich sein Elternprozess beendet, wird er terminiert.
Zusäztlich bietet die \lstinline$Process$-Klasse noch weitere Attribute und Methoden an.
Über das \lstinline$pid$-Attribut kann die ID des jeweiligen Prozesses abgefragt werden. 
Durch \lstinline$exitcode$ kann abgefragt werden, mit welchem Status sich der Prozess beendet hat.
Wurde er noch nicht beendet, hat \lstinline$exitcode$ den Wert \lstinline$None$.
Trägt \lstinline$exitcode$ einen negativen Wert, so bedeutet das, dass der Prozess durch ein Signal
beendet wurde.
Ein Wert von \lstinline$-N$ entspricht dann dem Signal \lstinline$N$.
Beim Attribut \lstinline$authkey$ handelt es sich um einen Byte-String, welcher für gewisse
Authentifizierungen genutzt wird und standardmäßig den Wert des Elternprozesses übernimmt.
Genauere Informationen zur Verwendung von \lstinline$authkey$ sind in \cite{pythondokuprozesse}
 zu finden.
Die beiden Methoden \lstinline$kill()$ und \lstinline$terminate()$ beenden den jeweiligen Prozess, nicht
aber dessen Kindprozesse.
Verwendet der Prozess \lstinline$Locks$, \lstinline$Semaphoren$, \lstinline$Queues$ oder \lstinline$Pipes$,
so kann ein Aufruf der beiden Methoden dazu führen, dass die verwendeten Objekte unnutzbar werden 
und andere Prozesse in einen Deadlock geraten.
Unter Windows wird zum Beenden der Prozesse \lstinline$TerminateProcess()$ aufgerufen.
Unter Unix-Systemen sendet die Methode \lstinline$terminate()$ das \lstinline$SIG-$ \lstinline$TERM$
Signal, während \lstinline$kill()$ das Signal \lstinline$SIGKKILL$ sendet.
Durch Aufruf der \lstinline$close()$-Methode werden alle Resourcen des jeweiligen Prozesses freigegeben,
falls er bereits beendet ist.
Andernfalls wird ein \lstinline$ValueError$ geworfen.
Nachdem \lstinline$close()$ erfolgreich zurückgekehrt ist, wird beim Zugriff auf die meisten Methoden 
und Attributen von \lstinline$Process$ ebenfalls ein \lstinline$ValueError$ geworfen.

\warning{
Die Methoden \lstinline$start()$, \lstinline$join()$, \lstinline$is_alive()$, \lstinline$terminate()$ und das
Attribut \lstinline$exitcode$ sollten immer nur vom erzeugenden Prozess verwendet werden.
}

Das \lstinline$multiprocessing$-Modul unterstützt, je nach Betriebssystem, drei verschiedene Arten einen
Prozess zu starten.
Bei diesen drei Arten handelt es sich um \lstinline$spawn$, \lstinline$fork$ und \lstinline$forkserver$,
welche sich folgendermaßen unterscheiden:

\begin{enumerate}
\item \lstinline$spawn$: \newline
Diese Art der Prozesserzeugung starten einen neuen Python Interpreter. 
Es werden nur diejenigen Resourcen an den neuen Prozess vererbt, die zum Ausführen seiner 
\lstinline$run()$-Methode nötig sind.
Im Vergleich zu den beiden anderen Varianten ist diese eher langsam.
Sie ist unter Unix und Windows Systemen verfügbar und der Standard unter Windows.

\item \lstinline$fork$: \newline
Durch diese Startmethode wird ein Fork des aktuellen Python Interpreters durch den Aufruf von 
\lstinline$os.fork()$ erstellt.
Das heißt, dass der erzeugte Kindprozess effektiv identisch zum Elternprozess ist. 
Alle Resourcen werden vom Elternprozess geerbt.
Erzeugen Multithreaded-Prozesse mit dieser Startmethode Kindprozesse, kann es sehr schnell
problematisch werden.
Unter Windows ist diese Startmethode nicht verfügbar, unter Unix Systemen ist sie die Standardvariante.

\item \lstinline$forkserver$: \newline
Wurde beim Starten des Programms diese Variante zum Starten von Prozessen gewählt, wird ein Server 
gestartet.
Immer wenn ein neuer Prozess erzeugt werden soll, verbindet sich der erzeugende Prozess mit diesem
Server und fordert an, einen Fork erstellen zu lassen.
Hierbei werden nur die notwendigen Resourcen an den Kindprozess vererbt.
Da es sich bei dem Fork-Server um einen Single-Threaded-Prozess handelt, ist ein Aufruf von 
\lstinline$os.fork()$ unproblematisch.
Diese Variante wird nur von Unix Systemen unterstützt, die auch das übergeben von Dateideskriptoren 
über Unix-Pipes unterstützen.
\end{enumerate}

Um eine der drei Startmethoden zu wählen, kann die \lstinline$set_start_method()$-Methode aufgerufen 
werden.
Sie sollte nur innerhalb von \lstinline$if __name__ ==$ \lstinline$''__main__''$ aufgerufen werden und nie mehrmals
in einem Programm.
Die \lstinline$spawn$ Startmethode wird also wie im
\hyperref[prozesse:lst:prozess_start_methode]{folgenden Beispiel} gezeigt ausgewählt.

\label{prozesse:lst:prozess_start_methode}
\lstinputlisting[language=Python,linerange={1-2,11-16}]{chapters/nebenlaufigkeit/src/prozess_start_methode.py}

Sollen mehrere Prozesse mit unterschiedlichen Startmethoden gestartet werden, so kann alternativ
\lstinline$get_context()$ aufgrufen werden, um ein \lstinline$Context$-Objekt zu erhalten.
Hierbei ist darauf zu achten, dass Objekte, welche mit einem \lstinline$Context$ erzeugt wurden, nicht
immer kompatibel mit Prozessen sind, welche mit einem anderen \lstinline$Context$ gestartet wurden.
So ist ein \lstinline$Lock$-Objekt, welches mit einem \lstinline$fork-Context$ erzeugt wurde, nicht mit
Prozessen kompatibel, die mittels der \lstinline$spawn$ oder der \lstinline$forkserver$ Startmethode 
erzeugt wurden.
Im folgenden \hyperref[prozesse:lst:prozess_start_methode_context]{Beispiel} ist gezeigt,
wie ein Prozess mit einer bestimmten Startmethode durch ein \lstinline$Context$-Objekt erzeugt wird.

\label{prozesse:lst:prozess_start_methode_context}
\lstinputlisting[language=Python,linerange={1-2,17-22}]{chapters/nebenlaufigkeit/src/prozess_start_methode.py}

\uebung
\aufgabe{nebenlaufigkeit11}

Häufig wird eine Aufgabe in kleinere Schritte unterteilt und dann an mehrere Arbeiterprozesse aufgeteilt.
Ein Beispiel hierfür ist das vorherige \hyperref[prozesse:lst:primzahlen_prozesse]{Zählen von Primzahlen}.
\randnotiz{Prozess-Pools}
Für solche Fälle existiert in Python die \lstinline$Pool$-Klasse, welche das Auslagern von Aufgaben an 
Arbeiterprozesse erleichtert.
Wird ein neuer \lstinline$Pool$ erzeugt, kann seinem Konstruktor über den Parameter \lstinline$processes$
die Anzahl der Arbeiterthreads mitgegeben werden.
Werden die Parameter \lstinline$initializer$ und \lstinline$initargs$ angeben, so wird das Callable-Objekt,
welches an \lstinline$initializer$ übergeben wurde, von jedem der Arbeiterprozesse mit \lstinline$initargs$
als Parameter aufgerufen, wenn die Arbeiterprozesse gestartet werden.
Durch \lstinline$maxtasksperchild$ wird die maximale Anzahl an Aufgaben, welche die Arbeiterprozesse 
abarbeitern, angegeben, bevor sie beendet und von einem neuen Arbeiterprozess ersetzt werden. 
Dies hat zur Folge, dass ungenutzte Resourcen wieder freigegeben werden.
Der letzte Parameter ist \lstinline$context$.
Wird er angegeben, so werden die Arbeiterprozesse mit dem angegebenen \lstinline$Context$-Objekt 
erzeugt.
Um den erzeugten Arbeiterprozessen Aufgaben zu übergeben, bietet \lstinline$Pool$ verschiedene
Methoden an.
Diese sollten immer nur von dem Prozess aufgerufen werden, der auch den \lstinline$Pool$ erzeugt hat.
Durch \lstinline$apply()$  wird von einem der Arbeiterprozesse das Callable-Objekt, welches über den
Parameter \lstinline$func$ angegeben wird, mit den Parametern, welche durch \lstinline$args$ angegeben
wurden, aufgerufen.
Es ist auch möglich Schlüsselwort-Parameter über \lstinline$kwds$ anzugeben.
Der Aufruf von \lstinline$apply$ blockiert, bis die Aufgabe abgearbeitet wurde.
Die beiden Methoden \lstinline$map()$ und \lstinline$imap()$ nehmen ebenfalls ein Callable-Objekt
mit dem \lstinline$func$ Parameter entgegen.
Durch den Parameter \lstinline$iterable$ kann ein Iterable-Objekt übergeben werden, welches 
aufgeteilt wird und den Arbeiterprozessen als seperate Aufgaben übergeben wird.
Der Aufruf der beiden Methoden blockiert, bis die Aufgaben abgearbeitet wurden.
Bei sehr langen Iterable-Objekten ist \lstinline$imap()$ effizienter.
Ist die Reihenfolge der Ergebnisse irrelevant, kann auch \lstinline$imap_unordered()$ genutzt werden,
welche sich andernfalls genau wie \lstinline$imap()$ verhält.
Benötigt eine Aufgabe eine Parameterlist, welche größer 1 ist, kann \lstinline$starmap()$ angewendet 
werden.
Hierbei wird davon ausgegangen, dass die Elemente des Iterable-Objektes, welches an \lstinline$iterable$
übergeben wird, ebenfalls Iterable-Objekte sind.
Diese werden als Parameter für das Callable-Objekte in \lstinline$func$ entpackt.
Wie die ersten 10 Quadratzahlen mit einem Pool aus 5 Prozessen berechnet werden können, wird im 
\hyperref[prozesse:lst:prozess_pool]{folgenden Beispiel} gezeigt.

\label{prozesse:lst:prozess_pool}
\lstinputlisting[language=Python,linerange={1-2,6-14}]{chapters/nebenlaufigkeit/src/prozess_pool.py}

Die Methoden \lstinline$apply_async()$, \lstinline$map_async()$ und \lstinline$startmap_async()$ verhalten
sich wie ihre normalen Varianten, aber sie blockieren nicht.
Sie geben ein \lstinline$AsyncResult$-Objekt zurück, über das das Ergebnis der Aufgaben erhalten 
werden kann, sobald es verfügbar ist.
Die Methode \lstinline$ready()$ gibt an, ob die Aufgaben bereits abgearbeitet wurden.
Durch \lstinline$successful()$ kann erfahren werden, ob eine Exception während dem Bearbeiten der 
Aufgaben geworfen wurde. 
Wurden noch nicht alle Aufgaben vollständig beabreitet, wird ein \lstinline$AssertionError$ geworfen.
Soll darauf gewartet werden, dass alle Aufgaben abgearbeitet wurden, kann \lstinline$wait()$ aufgerufen
werden.
Um das Ergebnis der Aufgaben zu erhalten, kann \lstinline$get()$ aufgerufen werden.
Für \lstinline$wait()$ und \lstinline$get()$ kann ein optionaler Timeout angegeben werden.
Wurden alle Aufgaben an den \lstinline$Pool$ übergeben, kann \lstinline$close()$ aufgerufen werden.
Nachdem diese Methode aufgerufen wurde, kann dem \lstinline$Pool$ keine neue Aufgabe
übergeben werden.
Sobald alle Aufgaben abgearbeitet wurden, werden die Arbeiterprozesse beendet.
Durch den Aufruf von \lstinline$terminate()$ werden die Arbeiterprozesse sofort beendet, ohne dass sie
ihre Aufgaben fertig bearbeiten.
Nachdem einer dieser beiden Methoden aufgerufen wurde, kann durch \lstinline$join()$ darauf gewartet
werden, dass sich alle Arbeiterprozesse beenden.

\uebung
\aufgabe{nebenlaufigkeit12}


\subsubsection{Prozess-Kommunikation}
\label{prozesse:subsubsection:prozess-kommunikation}

Um Daten zwischen Prozessen auszutauschen bietet Python die \lstinline$Pipe$- Funktion und die
\lstinline$Queue$-Klasse an.
Dieser \lstinline$Queue$ aus dem \lstinline$multiprocessing$- Modul ist dem bereits bekannten
\lstinline$Queue$ aus dem \lstinline$queue$-Modul sehr ähnlich.
Intern wird eine Pipe genutzt, welche durch \lstinline$Locks$ und \lstinline$Semaphoren$ 
geschützt wird.
Wird von einem Prozess zum ersten Mal ein Element hinzugefügt, wird ein neuer Thread gestartet, der das
Element aus einem Puffer in die Pipe schreibt.
Die \lstinline$Queue$-Klasse implementiert alle bekannten Methoden, bis auf \lstinline$join()$ und 
\lstinline$task_done()$.
\randnotiz{Queues}
Darüber hinaus werden auch neue Methoden implementiert.
Durch \lstinline$close()$  wird der \lstinline$Queue$ signalisiert, dass der aufrufende Prozesse keine neuen
Daten mehr hinzufügt.
Sobald alle Elemente aus dem Puffer in die Pipe geschrieben wurden, beendet sich der
Hintergrundthread.
Durch den Aufruf von \lstinline$join_thread()$ kann auf dieses Ereignis gewartet warten.
Es kann auch \lstinline$cancel_join_thread()$ aufgerufen werden, wenn der Prozess sofort beendet 
werden soll, ohne dass die Elemente aus dem Puffer in die Pipe geschrieben werden.
Neben \lstinline$Queue$ wird auch ein \lstinline$SimpleQueue$ angeboten.
Er besitzt nur drei Methoden, \lstinline$empty()$, \lstinline$get()$ und \lstinline$put()$, welche alle
selbsterklärend sind.
Darüber hinaus wird die \lstinline$JoinableQueue$-Klasse angeboten.
Sie erbt von \lstinline$Queue$ und erweitert diese Funktionalität um die beiden Methoden 
\lstinline$task_done()$ und \lstinline$join()$, welche sich wie die bereits bekannten Methoden verhalten.
Die \lstinline$Pipe()$-Funktion gibt zwei \lstinline$Connection$-Objekte zurück, welche über eine Pipe
verbunden sind.
\randnotiz{Pipes}
Jedes Ende der Pipe wird durch eines der beiden \lstinline$Connection$-Objekte repräsentiert.
Sollten zwei Prozesse oder Threads gleichzeitig versuchen von einem Ende der Pipe zu lesen oder hinein zu
schreiben, so können die Daten in der Pipe korrupiert werden.
Die beiden \lstinline$Connection$-Objekte bieten die \lstinline$send()$-Methode an, welche das 
übergebene Objekt an das andere Ende der \lstinline$Connection$ überträgt.
Wird auf der anderen Seite \lstinline$recv()$ aufgerufen, wird das übertragene Objekt empfangen.
Wenn noch keine Objekt gesendet wurde, blockiert \lstinline$recv()$ bis ein Objekt zum Empfang 
bereit ist.
Um eine \lstinline$Connection$ zu schließen, muss \lstinline$close()$ aufgerufen werden.
Die Methode \lstinline$poll()$ gibt an, ob aktuell Daten zum Empfangen bereit sind.
Es ist möglich, einen optionalen Timeout anzugeben.
Die \lstinline$poll()$-Methode blockiert dann maximal die spezifizierte Zeit in Sekunden.
Wurde kein Timeout angegeben, kehrt die Methode sofort zurück.
Sollen Byte-Daten versendet werden, kann die Methode \lstinline$send_bytes()$ aufgerufen werden.
Sie nimmt ein Objekt entgegen, das das Buffer Protokoll (vgl. \cite{bufferproto}) unterstützt,
und einen optionalen Offset.
Durch \lstinline$recv_bytes()$ kann dieses Objekt empfangen werden.
Sollte aktuell nichts zu empfangen sein, blockiert \lstinline$recv_bytes()$.
Es kann optional eine maximale Länge über \lstinline$maxlength$ angegeben werden.

\warning{
Sollte die empfangene Nachricht allerdings größer sein als die angegebene Länge, wird ein \lstinline
$OSError$ geworfen und von der \lstinline$Connection$ kann nicht weiter gelesen werden.
}

Alternativ kann \lstinline$recv_bytes_into()$ genutzt werden.
Diese Methode gibt die Anzahl der empfangenen Bytes zurück und schreibt sie in das durch den 
Parameter \lstinline$buffer$ angegebene Objekt.
Es kann zudem ein optionaler Parameter \lstinline$offset$ angegeben werden, um die Startposition im
Buffer zu definieren.
Sollten keine Daten empfangsbereit sein, blockiert \lstinline$recv_bytes_into()$.

\uebung
\aufgabe{nebenlaufigkeit13}